{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "# preprocessing train & test\n",
    "def train_test(num_rows=None):\n",
    "\n",
    "    # load csv\n",
    "    train_df = pd.read_csv('../input/train.csv', index_col=['card_id'], nrows=num_rows)\n",
    "    test_df = pd.read_csv('../input/test.csv', index_col=['card_id'], nrows=num_rows)\n",
    "\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(train_df), len(test_df)))\n",
    "\n",
    "    # outlier\n",
    "    train_df['outliers'] = 0\n",
    "    train_df.loc[train_df['target'] < -30, 'outliers'] = 1\n",
    "\n",
    "    # set target as nan\n",
    "    test_df['target'] = np.nan\n",
    "\n",
    "    # merge\n",
    "    df = train_df.append(test_df)\n",
    "\n",
    "    del train_df, test_df\n",
    "    gc.collect()\n",
    "\n",
    "    # to datetime\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "\n",
    "    # datetime features\n",
    "    df['quarter'] = df['first_active_month'].dt.quarter\n",
    "    df['elapsed_time'] = (datetime.datetime.today() - df['first_active_month']).dt.days\n",
    "\n",
    "    df['days_feature1'] = df['elapsed_time'] * df['feature_1']\n",
    "    df['days_feature2'] = df['elapsed_time'] * df['feature_2']\n",
    "    df['days_feature3'] = df['elapsed_time'] * df['feature_3']\n",
    "\n",
    "    df['days_feature1_ratio'] = df['feature_1'] / df['elapsed_time']\n",
    "    df['days_feature2_ratio'] = df['feature_2'] / df['elapsed_time']\n",
    "    df['days_feature3_ratio'] = df['feature_3'] / df['elapsed_time']\n",
    "\n",
    "    # one hot encoding\n",
    "    df, cols = one_hot_encoder(df, nan_as_category=False)\n",
    "\n",
    "    for f in ['feature_1','feature_2','feature_3']:\n",
    "        order_label = df.groupby([f])['outliers'].mean()\n",
    "        df[f] = df[f].map(order_label)\n",
    "\n",
    "    df['feature_sum'] = df['feature_1'] + df['feature_2'] + df['feature_3']\n",
    "    df['feature_mean'] = df['feature_sum']/3\n",
    "    df['feature_max'] = df[['feature_1', 'feature_2', 'feature_3']].max(axis=1)\n",
    "    df['feature_min'] = df[['feature_1', 'feature_2', 'feature_3']].min(axis=1)\n",
    "    df['feature_var'] = df[['feature_1', 'feature_2', 'feature_3']].std(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# preprocessing historical transactions\n",
    "def historical_transactions(num_rows=None):\n",
    "    # load csv\n",
    "    hist_df = pd.read_csv('../input/historical_transactions.csv', nrows=num_rows)\n",
    "\n",
    "    # fillna\n",
    "    hist_df['category_2'].fillna(1.0,inplace=True)\n",
    "    hist_df['category_3'].fillna('A',inplace=True)\n",
    "    hist_df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)\n",
    "    hist_df['installments'].replace(-1, np.nan,inplace=True)\n",
    "    hist_df['installments'].replace(999, np.nan,inplace=True)\n",
    "\n",
    "    # trim\n",
    "    hist_df['purchase_amount'] = hist_df['purchase_amount'].apply(lambda x: min(x, 0.8))\n",
    "\n",
    "    # Y/N to 1/0\n",
    "    hist_df['authorized_flag'] = hist_df['authorized_flag'].map({'Y': 1, 'N': 0}).astype(int)\n",
    "    hist_df['category_1'] = hist_df['category_1'].map({'Y': 1, 'N': 0}).astype(int)\n",
    "    hist_df['category_3'] = hist_df['category_3'].map({'A':0, 'B':1, 'C':2})\n",
    "\n",
    "    # datetime features\n",
    "    hist_df['purchase_date'] = pd.to_datetime(hist_df['purchase_date'])\n",
    "    hist_df['month'] = hist_df['purchase_date'].dt.month\n",
    "    hist_df['day'] = hist_df['purchase_date'].dt.day\n",
    "    hist_df['hour'] = hist_df['purchase_date'].dt.hour\n",
    "    hist_df['weekofyear'] = hist_df['purchase_date'].dt.weekofyear\n",
    "    hist_df['weekday'] = hist_df['purchase_date'].dt.weekday\n",
    "    hist_df['weekend'] = (hist_df['purchase_date'].dt.weekday >=5).astype(int)\n",
    "\n",
    "    # additional features\n",
    "    hist_df['price'] = hist_df['purchase_amount'] / hist_df['installments']\n",
    "\n",
    "    #Christmas : December 25 2017\n",
    "    hist_df['Christmas_Day_2017']=(pd.to_datetime('2017-12-25')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Mothers Day: May 14 2017\n",
    "    hist_df['Mothers_Day_2017']=(pd.to_datetime('2017-06-04')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #fathers day: August 13 2017\n",
    "    hist_df['fathers_day_2017']=(pd.to_datetime('2017-08-13')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Childrens day: October 12 2017\n",
    "    hist_df['Children_day_2017']=(pd.to_datetime('2017-10-12')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Valentine's Day : 12th June, 2017\n",
    "    hist_df['Valentine_Day_2017']=(pd.to_datetime('2017-06-12')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Black Friday : 24th November 2017\n",
    "    hist_df['Black_Friday_2017']=(pd.to_datetime('2017-11-24') - hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "    #2018\n",
    "    #Mothers Day: May 13 2018\n",
    "    hist_df['Mothers_Day_2018']=(pd.to_datetime('2018-05-13')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "    hist_df['month_diff'] = ((datetime.datetime.today() - hist_df['purchase_date']).dt.days)//30\n",
    "    hist_df['month_diff'] += hist_df['month_lag']\n",
    "\n",
    "    # additional features\n",
    "    hist_df['duration'] = hist_df['purchase_amount']*hist_df['month_diff']\n",
    "    hist_df['amount_month_ratio'] = hist_df['purchase_amount']/hist_df['month_diff']\n",
    "\n",
    "    # reduce memory usage\n",
    "    hist_df = reduce_mem_usage(hist_df)\n",
    "\n",
    "    col_unique =['subsector_id', 'merchant_id', 'merchant_category_id']\n",
    "    col_seas = ['month', 'hour', 'weekofyear', 'weekday', 'day']\n",
    "\n",
    "    aggs = {}\n",
    "    for col in col_unique:\n",
    "        aggs[col] = ['nunique']\n",
    "\n",
    "    for col in col_seas:\n",
    "        aggs[col] = ['nunique', 'mean', 'min', 'max']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var','skew']\n",
    "    aggs['installments'] = ['sum','max','mean','var','skew']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_lag'] = ['max','min','mean','var','skew']\n",
    "    aggs['month_diff'] = ['max','min','mean','var','skew']\n",
    "    aggs['authorized_flag'] = ['mean']\n",
    "    aggs['weekend'] = ['mean'] # overwrite\n",
    "    aggs['weekday'] = ['mean'] # overwrite\n",
    "    aggs['day'] = ['nunique', 'mean', 'min'] # overwrite\n",
    "    aggs['category_1'] = ['mean']\n",
    "    aggs['category_2'] = ['mean']\n",
    "    aggs['category_3'] = ['mean']\n",
    "    aggs['card_id'] = ['size','count']\n",
    "    aggs['price'] = ['sum','mean','max','min','var']\n",
    "    aggs['Christmas_Day_2017'] = ['mean']\n",
    "    aggs['Mothers_Day_2017'] = ['mean']\n",
    "    aggs['fathers_day_2017'] = ['mean']\n",
    "    aggs['Children_day_2017'] = ['mean']\n",
    "    aggs['Valentine_Day_2017'] = ['mean']\n",
    "    aggs['Black_Friday_2017'] = ['mean']\n",
    "    aggs['Mothers_Day_2018'] = ['mean']\n",
    "    aggs['duration']=['mean','min','max','var','skew']\n",
    "    aggs['amount_month_ratio']=['mean','min','max','var','skew']\n",
    "\n",
    "    for col in ['category_2','category_3']:\n",
    "        hist_df[col+'_mean'] = hist_df.groupby([col])['purchase_amount'].transform('mean')\n",
    "        hist_df[col+'_min'] = hist_df.groupby([col])['purchase_amount'].transform('min')\n",
    "        hist_df[col+'_max'] = hist_df.groupby([col])['purchase_amount'].transform('max')\n",
    "        hist_df[col+'_sum'] = hist_df.groupby([col])['purchase_amount'].transform('sum')\n",
    "        aggs[col+'_mean'] = ['mean']\n",
    "\n",
    "    hist_df = hist_df.reset_index().groupby('card_id').agg(aggs)\n",
    "\n",
    "    # change column name\n",
    "    hist_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in hist_df.columns.tolist()])\n",
    "    hist_df.columns = ['hist_'+ c for c in hist_df.columns]\n",
    "\n",
    "    hist_df['hist_purchase_date_diff'] = (hist_df['hist_purchase_date_max']-hist_df['hist_purchase_date_min']).dt.days\n",
    "    hist_df['hist_purchase_date_average'] = hist_df['hist_purchase_date_diff']/hist_df['hist_card_id_size']\n",
    "    hist_df['hist_purchase_date_uptonow'] = (datetime.datetime.today()-hist_df['hist_purchase_date_max']).dt.days\n",
    "    hist_df['hist_purchase_date_uptomin'] = (datetime.datetime.today()-hist_df['hist_purchase_date_min']).dt.days\n",
    "\n",
    "    # reduce memory usage\n",
    "    hist_df = reduce_mem_usage(hist_df)\n",
    "\n",
    "    return hist_df\n",
    "    \n",
    "# preprocessing new_merchant_transactions\n",
    "def new_merchant_transactions(num_rows=None):\n",
    "    # load csv\n",
    "    new_merchant_df = pd.read_csv('../input/new_merchant_transactions.csv', nrows=num_rows)\n",
    "\n",
    "    # fillna\n",
    "    new_merchant_df['category_2'].fillna(1.0,inplace=True)\n",
    "    new_merchant_df['category_3'].fillna('A',inplace=True)\n",
    "    new_merchant_df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)\n",
    "    new_merchant_df['installments'].replace(-1, np.nan,inplace=True)\n",
    "    new_merchant_df['installments'].replace(999, np.nan,inplace=True)\n",
    "\n",
    "    # trim\n",
    "    new_merchant_df['purchase_amount'] = new_merchant_df['purchase_amount'].apply(lambda x: min(x, 0.8))\n",
    "\n",
    "    # Y/N to 1/0\n",
    "    new_merchant_df['authorized_flag'] = new_merchant_df['authorized_flag'].map({'Y': 1, 'N': 0}).astype(int)\n",
    "    new_merchant_df['category_1'] = new_merchant_df['category_1'].map({'Y': 1, 'N': 0}).astype(int)\n",
    "    new_merchant_df['category_3'] = new_merchant_df['category_3'].map({'A':0, 'B':1, 'C':2}).astype(int)\n",
    "\n",
    "    # datetime features\n",
    "    new_merchant_df['purchase_date'] = pd.to_datetime(new_merchant_df['purchase_date'])\n",
    "    new_merchant_df['month'] = new_merchant_df['purchase_date'].dt.month\n",
    "    new_merchant_df['day'] = new_merchant_df['purchase_date'].dt.day\n",
    "    new_merchant_df['hour'] = new_merchant_df['purchase_date'].dt.hour\n",
    "    new_merchant_df['weekofyear'] = new_merchant_df['purchase_date'].dt.weekofyear\n",
    "    new_merchant_df['weekday'] = new_merchant_df['purchase_date'].dt.weekday\n",
    "    new_merchant_df['weekend'] = (new_merchant_df['purchase_date'].dt.weekday >=5).astype(int)\n",
    "\n",
    "    # additional features\n",
    "    new_merchant_df['price'] = new_merchant_df['purchase_amount'] / new_merchant_df['installments']\n",
    "\n",
    "    #Christmas : December 25 2017\n",
    "    new_merchant_df['Christmas_Day_2017']=(pd.to_datetime('2017-12-25')-new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Childrens day: October 12 2017\n",
    "    new_merchant_df['Children_day_2017']=(pd.to_datetime('2017-10-12')-new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Black Friday : 24th November 2017\n",
    "    new_merchant_df['Black_Friday_2017']=(pd.to_datetime('2017-11-24') - new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "    #Mothers Day: May 13 2018\n",
    "    new_merchant_df['Mothers_Day_2018']=(pd.to_datetime('2018-05-13')-new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "    new_merchant_df['month_diff'] = ((datetime.datetime.today() - new_merchant_df['purchase_date']).dt.days)//30\n",
    "    new_merchant_df['month_diff'] += new_merchant_df['month_lag']\n",
    "\n",
    "    # additional features\n",
    "    new_merchant_df['duration'] = new_merchant_df['purchase_amount']*new_merchant_df['month_diff']\n",
    "    new_merchant_df['amount_month_ratio'] = new_merchant_df['purchase_amount']/new_merchant_df['month_diff']\n",
    "\n",
    "    # reduce memory usage\n",
    "    new_merchant_df = reduce_mem_usage(new_merchant_df)\n",
    "\n",
    "    col_unique =['subsector_id', 'merchant_id', 'merchant_category_id']\n",
    "    col_seas = ['month', 'hour', 'weekofyear', 'weekday', 'day']\n",
    "\n",
    "    aggs = {}\n",
    "    for col in col_unique:\n",
    "        aggs[col] = ['nunique']\n",
    "\n",
    "    for col in col_seas:\n",
    "        aggs[col] = ['nunique', 'mean', 'min', 'max']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var','skew']\n",
    "    aggs['installments'] = ['sum','max','mean','var','skew']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_lag'] = ['max','min','mean','var','skew']\n",
    "    aggs['month_diff'] = ['mean','var','skew']\n",
    "    aggs['weekend'] = ['mean']\n",
    "    aggs['month'] = ['mean', 'min', 'max']\n",
    "    aggs['weekday'] = ['mean', 'min', 'max']\n",
    "    aggs['category_1'] = ['mean']\n",
    "    aggs['category_2'] = ['mean']\n",
    "    aggs['category_3'] = ['mean']\n",
    "    aggs['card_id'] = ['size','count']\n",
    "    aggs['price'] = ['mean','max','min','var']\n",
    "    aggs['Christmas_Day_2017'] = ['mean']\n",
    "    aggs['Children_day_2017'] = ['mean']\n",
    "    aggs['Black_Friday_2017'] = ['mean']\n",
    "    aggs['Mothers_Day_2018'] = ['mean']\n",
    "    aggs['duration']=['mean','min','max','var','skew']\n",
    "    aggs['amount_month_ratio']=['mean','min','max','var','skew']\n",
    "\n",
    "    for col in ['category_2','category_3']:\n",
    "        new_merchant_df[col+'_mean'] = new_merchant_df.groupby([col])['purchase_amount'].transform('mean')\n",
    "        new_merchant_df[col+'_min'] = new_merchant_df.groupby([col])['purchase_amount'].transform('min')\n",
    "        new_merchant_df[col+'_max'] = new_merchant_df.groupby([col])['purchase_amount'].transform('max')\n",
    "        new_merchant_df[col+'_sum'] = new_merchant_df.groupby([col])['purchase_amount'].transform('sum')\n",
    "        aggs[col+'_mean'] = ['mean']\n",
    "\n",
    "    new_merchant_df = new_merchant_df.reset_index().groupby('card_id').agg(aggs)\n",
    "\n",
    "    # change column name\n",
    "    new_merchant_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in new_merchant_df.columns.tolist()])\n",
    "    new_merchant_df.columns = ['new_'+ c for c in new_merchant_df.columns]\n",
    "\n",
    "    new_merchant_df['new_purchase_date_diff'] = (new_merchant_df['new_purchase_date_max']-new_merchant_df['new_purchase_date_min']).dt.days\n",
    "    new_merchant_df['new_purchase_date_average'] = new_merchant_df['new_purchase_date_diff']/new_merchant_df['new_card_id_size']\n",
    "    new_merchant_df['new_purchase_date_uptonow'] = (datetime.datetime.today()-new_merchant_df['new_purchase_date_max']).dt.days\n",
    "    new_merchant_df['new_purchase_date_uptomin'] = (datetime.datetime.today()-new_merchant_df['new_purchase_date_min']).dt.days\n",
    "\n",
    "    # reduce memory usage\n",
    "    new_merchant_df = reduce_mem_usage(new_merchant_df)\n",
    "\n",
    "    return new_merchant_df\n",
    "\n",
    "# additional features\n",
    "def additional_features(df):\n",
    "    df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['hist_last_buy'] = (df['hist_purchase_date_max'] - df['first_active_month']).dt.days\n",
    "    df['new_first_buy'] = (df['new_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['new_last_buy'] = (df['new_purchase_date_max'] - df['first_active_month']).dt.days\n",
    "\n",
    "    date_features=['hist_purchase_date_max','hist_purchase_date_min',\n",
    "                   'new_purchase_date_max', 'new_purchase_date_min']\n",
    "\n",
    "    for f in date_features:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "\n",
    "    df['card_id_total'] = df['new_card_id_size']+df['hist_card_id_size']\n",
    "    df['card_id_cnt_total'] = df['new_card_id_count']+df['hist_card_id_count']\n",
    "    df['card_id_cnt_ratio'] = df['new_card_id_count']/df['hist_card_id_count']\n",
    "    df['purchase_amount_total'] = df['new_purchase_amount_sum']+df['hist_purchase_amount_sum']\n",
    "    df['purchase_amount_mean'] = df['new_purchase_amount_mean']+df['hist_purchase_amount_mean']\n",
    "    df['purchase_amount_max'] = df['new_purchase_amount_max']+df['hist_purchase_amount_max']\n",
    "    df['purchase_amount_min'] = df['new_purchase_amount_min']+df['hist_purchase_amount_min']\n",
    "    df['purchase_amount_ratio'] = df['new_purchase_amount_sum']/df['hist_purchase_amount_sum']\n",
    "    df['month_diff_mean'] = df['new_month_diff_mean']+df['hist_month_diff_mean']\n",
    "    df['month_diff_ratio'] = df['new_month_diff_mean']/df['hist_month_diff_mean']\n",
    "    df['month_lag_mean'] = df['new_month_lag_mean']+df['hist_month_lag_mean']\n",
    "    df['month_lag_max'] = df['new_month_lag_max']+df['hist_month_lag_max']\n",
    "    df['month_lag_min'] = df['new_month_lag_min']+df['hist_month_lag_min']\n",
    "    df['category_1_mean'] = df['new_category_1_mean']+df['hist_category_1_mean']\n",
    "    df['installments_total'] = df['new_installments_sum']+df['hist_installments_sum']\n",
    "    df['installments_mean'] = df['new_installments_mean']+df['hist_installments_mean']\n",
    "    df['installments_max'] = df['new_installments_max']+df['hist_installments_max']\n",
    "    df['installments_ratio'] = df['new_installments_sum']/df['hist_installments_sum']\n",
    "    df['price_total'] = df['purchase_amount_total'] / df['installments_total']\n",
    "    df['price_mean'] = df['purchase_amount_mean'] / df['installments_mean']\n",
    "    df['price_max'] = df['purchase_amount_max'] / df['installments_max']\n",
    "    df['duration_mean'] = df['new_duration_mean']+df['hist_duration_mean']\n",
    "    df['duration_min'] = df['new_duration_min']+df['hist_duration_min']\n",
    "    df['duration_max'] = df['new_duration_max']+df['hist_duration_max']\n",
    "    df['amount_month_ratio_mean']=df['new_amount_month_ratio_mean']+df['hist_amount_month_ratio_mean']\n",
    "    df['amount_month_ratio_min']=df['new_amount_month_ratio_min']+df['hist_amount_month_ratio_min']\n",
    "    df['amount_month_ratio_max']=df['new_amount_month_ratio_max']+df['hist_amount_month_ratio_max']\n",
    "    df['new_CLV'] = df['new_card_id_count'] * df['new_purchase_amount_sum'] / df['new_month_diff_mean']\n",
    "    df['hist_CLV'] = df['hist_card_id_count'] * df['hist_purchase_amount_sum'] / df['hist_month_diff_mean']\n",
    "    df['CLV_ratio'] = df['new_CLV'] / df['hist_CLV']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
